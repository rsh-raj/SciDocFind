{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1k45ablN_4Yk",
        "ktTNg8MI_9Za",
        "wP-a_CnouMod",
        "_O1cy5qIsljF",
        "zdChexqrslWv",
        "eHHmzr8FAspY",
        "ALpEsSD_uYE3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This code performs the inference for all the fine-tuned models\n",
        "# Runs of CPU/GPU, faster on GPU\n",
        "\n",
        "# Similar to baselines.ipynb but the models are different\n",
        "# Please upload CSFCube-master.zip to the colab notebook\n",
        "# This zip file is present in our code base\n",
        "# fine-tuned models loaded from Google Drive"
      ],
      "metadata": {
        "id": "vIf6IHWIbcho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install libraries and prepare CSF-Cube dataset**"
      ],
      "metadata": {
        "id": "Y6g2BuNnboKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhsM02mGMFnv",
        "outputId": "83c1c0f4-242a-4c50-9986-0fefb7de1f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.7)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.27.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.7)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=e6a4f956e2aec02d2b67032e9c83e7085c358f1a2f17e6cb82ec8a06eea71a4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install gdown\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip CSFCube-master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNSYMssoMWK4",
        "outputId": "9993c999-7555-4fb7-c4e8-93f294a5ce0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CSFCube-master.zip\n",
            "   creating: CSFCube-master/\n",
            "  inflating: CSFCube-master/.gitignore  \n",
            "  inflating: CSFCube-master/LICENSE.md  \n",
            "  inflating: CSFCube-master/README.md  \n",
            "  inflating: CSFCube-master/abstracts-csfcube-preds.jsonl  \n",
            "  inflating: CSFCube-master/ann_guidelines.pdf  \n",
            "  inflating: CSFCube-master/datasheet.md  \n",
            "   creating: CSFCube-master/eval_scripts/\n",
            "  inflating: CSFCube-master/eval_scripts/rank_metrics.py  \n",
            "  inflating: CSFCube-master/eval_scripts/ranking_eval.py  \n",
            "  inflating: CSFCube-master/eval_scripts/requirements.txt  \n",
            "   creating: CSFCube-master/eval_scripts/sample_ranked_pools/\n",
            "  inflating: CSFCube-master/eval_scripts/sample_ranked_pools/test-pid2pool-csfcube-specter-background-ranked.json  \n",
            "  inflating: CSFCube-master/eval_scripts/sample_ranked_pools/test-pid2pool-csfcube-specter-method-ranked.json  \n",
            "  inflating: CSFCube-master/eval_scripts/sample_ranked_pools/test-pid2pool-csfcube-specter-result-ranked.json  \n",
            "  inflating: CSFCube-master/evaluation_splits.json  \n",
            "  inflating: CSFCube-master/queries-release.csv  \n",
            "  inflating: CSFCube-master/test-pid2anns-csfcube-background.json  \n",
            "  inflating: CSFCube-master/test-pid2anns-csfcube-method.json  \n",
            "  inflating: CSFCube-master/test-pid2anns-csfcube-result.json  \n",
            "  inflating: CSFCube-master/test-pid2pool-csfcube.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1THQvaypgyLgpOSHdHRMca7j1Rb44yLVe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq84R2bpNTkd",
        "outputId": "69468ecb-d1ab-4e65-9a05-03ecf2079b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1THQvaypgyLgpOSHdHRMca7j1Rb44yLVe\n",
            "To: /content/specter_triplet_4.pt\n",
            "100% 440M/440M [00:06<00:00, 63.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1PG7_SfihyL1OHEPR32SbFISqY6wyu4xc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3zDZBdqZisA",
        "outputId": "40ca9b21-2f9f-4f48-81c5-3385d735536a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PG7_SfihyL1OHEPR32SbFISqY6wyu4xc\n",
            "To: /content/scincl_triplet_4.pt\n",
            "100% 440M/440M [00:04<00:00, 101MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1ICTJSb6uziPbmbI4J12RnONNOx07y_O8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewD84yzEhjYC",
        "outputId": "8c7efd80-82a7-4144-fa65-8a801c792559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ICTJSb6uziPbmbI4J12RnONNOx07y_O8\n",
            "To: /content/finetuned-sentbert-pp-parade-train.pt\n",
            "100% 268M/268M [00:01<00:00, 217MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYQGpE8Ze3-N"
      },
      "source": [
        "# **Parse CSF-Cube dataset into Python dictionaries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gguE-1UOCXBF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def parse_dataset(file_data, file_background, file_method, file_result):\n",
        "    data = dict()\n",
        "    with open(file_data, 'r') as f:\n",
        "        abs_list = list(f)\n",
        "    for paper in abs_list:\n",
        "        paper = json.loads(paper)\n",
        "        dict_paper = dict()\n",
        "        dict_paper['title'] = paper['title']\n",
        "        dict_paper['abstract'] = paper['abstract']\n",
        "        dict_paper['pred_labels'] = paper['pred_labels']\n",
        "        try:\n",
        "            print(data[paper['paper_id']])\n",
        "        except:\n",
        "            data[paper['paper_id']] = dict_paper\n",
        "    file_list = [file_background, file_method, file_result]\n",
        "    result_list = []\n",
        "    for f in file_list:\n",
        "        with open(f, 'r') as json_file:\n",
        "            results_data = json.load(json_file)\n",
        "        result_dict = dict()\n",
        "        for k in results_data.keys():\n",
        "            try:\n",
        "                print(result_dict[k].keys())\n",
        "            except:\n",
        "                result_dict[k] = dict()\n",
        "            result_dict[k]['cands'] = results_data[k]['cands']\n",
        "            result_dict[k]['relevance_adju'] = results_data[k]['relevance_adju']\n",
        "        result_list.append(result_dict)\n",
        "    return data, result_list[0], result_list[1], result_list[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ZDgs5jCW9N"
      },
      "outputs": [],
      "source": [
        "sentences,bg_ranking,method_ranking,result_ranking = parse_dataset('/content/CSFCube-master/abstracts-csfcube-preds.jsonl','/content/CSFCube-master/test-pid2anns-csfcube-background.json','/content/CSFCube-master/test-pid2anns-csfcube-method.json','/content/CSFCube-master/test-pid2anns-csfcube-result.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load models**"
      ],
      "metadata": {
        "id": "MsLDGubBUauh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def init_model_tokenizer(i):\n",
        "    if(i==0):\n",
        "        tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
        "        model = AutoModel.from_pretrained('allenai/specter')\n",
        "    if i==3:\n",
        "        tokenizer = AutoTokenizer.from_pretrained('malteos/scincl')\n",
        "        model = AutoModel.from_pretrained('malteos/scincl')\n",
        "    if i==10:\n",
        "        model = SentenceTransformer('paraphrase-TinyBERT-L6-v2')\n",
        "        tokenizer = None\n",
        "\n",
        "    return model,tokenizer"
      ],
      "metadata": {
        "id": "3R-2yNDtMi_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model(model_id, model, tokenizer, texts, max_length):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    if model_id == 10:\n",
        "        model.eval()\n",
        "        cls_embeddings = model.encode(texts)\n",
        "        return cls_embeddings\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenizer(texts, max_length=max_length, truncation=True, padding=True, return_tensors='pt')\n",
        "        tokens.to(device)\n",
        "        outputs = model(**tokens)\n",
        "\n",
        "        # Get the output embeddings\n",
        "        embeddings = outputs.last_hidden_state\n",
        "        cls_embedding = embeddings[:, 0, :]\n",
        "        cls_embedding = cls_embedding.cpu().detach().numpy()\n",
        "        return cls_embedding"
      ],
      "metadata": {
        "id": "FhDuUcXjUXyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = [0,3,10]\n",
        "\n",
        "model_dict = dict()\n",
        "tokenizer_dict = dict()\n",
        "\n",
        "for k in keys:\n",
        "    model_dict[k],tokenizer_dict[k] = init_model_tokenizer(k)\n",
        "    model = model_dict[k]\n",
        "    if k==0:\n",
        "        model.load_state_dict(torch.load('/content/specter_triplet_4.pt', map_location=torch.device('cpu')))\n",
        "    elif k==3:\n",
        "        model.load_state_dict(torch.load('/content/scincl_triplet_4.pt', map_location=torch.device('cpu')))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load('/content/finetuned-sentbert-pp-parade-train.pt', map_location=torch.device('cpu')))\n",
        "    model_dict[k] = model"
      ],
      "metadata": {
        "id": "HmVk0W2XUXvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYuC9nxvfLcj"
      },
      "source": [
        "# **Ranked retrieval for candidates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldc06VWht78u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def L2_dist_ranking(cls_embeddings,query_id,cand_ids,results_dict):\n",
        "    query_cls = cls_embeddings[0]\n",
        "    # print(query_cls.shape,cls_embeddings.shape,len(cand_ids))\n",
        "    if query_id in results_dict.keys():\n",
        "        print('err')\n",
        "        return\n",
        "    results = []\n",
        "    for i in range(1,len(cls_embeddings)):\n",
        "        l2_norm = np.linalg.norm(query_cls - cls_embeddings[i])\n",
        "        results.append([cand_ids[i-1],l2_norm])\n",
        "    # print(results)\n",
        "    results = sorted(results, key = lambda x: x[1])\n",
        "    \n",
        "    for i in range(len(results)):\n",
        "        results[i][1] = float(results[i][1])\n",
        "    # print(results)\n",
        "    results_dict[query_id] = results\n",
        "    return\n",
        "\n",
        "def cosine_similarity(query_embeddings, cls_embeddings):\n",
        "    max_cosine_sim = 0.0\n",
        "    for embd_query in query_embeddings:\n",
        "        for embd_cand in cls_embeddings:\n",
        "            curr_cosine_sim = dot(embd_query, embd_cand)/(norm(embd_cand)*norm(embd_query))\n",
        "            if curr_cosine_sim > max_cosine_sim:\n",
        "                max_cosine_sim = curr_cosine_sim\n",
        "\n",
        "    return max_cosine_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N48JdHJt75Q"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def write_results(results_dict,model_name,facet):\n",
        "    file_name = \"test-pid2pool-csfcube-\" + model_name + \"-\" + facet + \"-ranked.json\"\n",
        "    with open(file_name,'w') as f:\n",
        "        json.dump(results_dict,f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hOa-IE0HcRu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def prepare_batch(query_id,data_dict,ranking_dict,query_facet,cand_facet):\n",
        "    titles = []\n",
        "    abstracts = []\n",
        "    query_title = data_dict[query_id]['title']\n",
        "    titles.append(query_title)\n",
        "    query_abstract = []\n",
        "    for i in range(len(data_dict[query_id]['abstract'])):\n",
        "        curr_label = data_dict[query_id]['pred_labels'][i]\n",
        "        if query_facet == \"abstract\" or query_facet == curr_label:\n",
        "            query_abstract.append(data_dict[query_id]['abstract'][i])\n",
        "        elif query_facet == \"background_label\" and curr_label==\"objective_label\":\n",
        "            query_abstract.append(data_dict[query_id]['abstract'][i])\n",
        "        elif query_facet == \"objective_label\" and curr_label==\"background_label\":\n",
        "            query_abstract.append(data_dict[query_id]['abstract'][i])\n",
        "    abstracts.append(query_abstract)\n",
        "\n",
        "    for j in range(len(ranking_dict[query_id]['cands'])):\n",
        "        cand_id = ranking_dict[query_id]['cands'][j]\n",
        "        cand_title = data_dict[cand_id]['title']\n",
        "        titles.append(cand_title)\n",
        "        cand_abstract = []\n",
        "        for i in range(len(data_dict[cand_id]['abstract'])):\n",
        "            curr_label = data_dict[cand_id]['pred_labels'][i]\n",
        "            if cand_facet == \"abstract\" or cand_facet == curr_label:\n",
        "                cand_abstract.append(data_dict[cand_id]['abstract'][i])\n",
        "            elif cand_facet == \"background_label\" and curr_label==\"objective_label\":\n",
        "                cand_abstract.append(data_dict[cand_id]['abstract'][i])\n",
        "            elif cand_facet == \"objective_label\" and curr_label==\"background_label\":\n",
        "                cand_abstract.append(data_dict[cand_id]['abstract'][i])\n",
        "        abstracts.append(cand_abstract)    \n",
        "\n",
        "    return titles,abstracts\n",
        "\n",
        "def eval_model(model_id, model_name, data_dict, ranking_dict, query_facet, cand_facet, ranking_facet):\n",
        "    model, tokenizer = model_dict[model_id], tokenizer_dict[model_id]\n",
        "    results_dict = dict()\n",
        "    for query_id in ranking_dict.keys():\n",
        "        batch_data = prepare_batch(query_id, data_dict, ranking_dict, query_facet, cand_facet)\n",
        "        if model_name == 'specter' or model_name == 'scincl' or model_name == 'scibert_uncased':\n",
        "            for i in range(len(batch_data[1])):\n",
        "                abs = \"\"\n",
        "                for j in batch_data[1][i]:\n",
        "                    abs += j\n",
        "                batch_data[1][i] = abs\n",
        "            title_abs = [batch_data[0][i] + tokenizer.sep_token +batch_data[1][i] for i in range(len(batch_data[0]))]\n",
        "            cls_embeddings = baseline_model(model_id, model, tokenizer, title_abs, 512)\n",
        "            L2_dist_ranking(cls_embeddings, query_id,ranking_dict[query_id]['cands'], results_dict)\n",
        "        else:\n",
        "            abstracts = batch_data[1]\n",
        "            results = []\n",
        "            if (len(batch_data[1][0]) == 0):\n",
        "                batch_data[1][0] = ['']\n",
        "            query_embeddings = baseline_model(10, model, None, batch_data[1][0], None)\n",
        "            for i in range(1, len(batch_data[1])):\n",
        "                if len(batch_data[1][i]) == 0:\n",
        "                    batch_data[1][i] = ['']\n",
        "                cls_embeddings = baseline_model(10, model, None, batch_data[1][i], None)\n",
        "                max_cosine_sim = cosine_similarity(query_embeddings, cls_embeddings)\n",
        "                results.append([ranking_dict[query_id]['cands'][i-1], max_cosine_sim])\n",
        "            results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "            for i in range(len(results)):\n",
        "                results[i][1] = float(results[i][1])\n",
        "            results_dict[query_id] = results\n",
        "        write_results(results_dict, model_name, ranking_facet)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k45ablN_4Yk"
      },
      "source": [
        "# specter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6JAx-D5EcU2"
      },
      "source": [
        "### Query Abstract - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqa4mA1xFPBx"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,bg_ranking,'abstract','abstract','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlpb_AUidoAV",
        "outputId": "ed0ceac5-bacb-4c97-b07d-9ecfa48d2b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2324, 0.2563, 0.4114, 0.7706, 0.5686, 0.5590\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1929, 0.2812, 0.4548, 0.7862, 0.5823, 0.5874\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sCvcTw8chk5"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,method_ranking,'abstract','abstract','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVyrzvnMdFjC",
        "outputId": "c3f6997e-3100-4b99-cea6-b79f8fb4b40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1235, 0.1500, 0.5350, 0.6403, 0.4127, 0.4099\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1153, 0.1389, 0.4781, 0.6439, 0.4159, 0.4100\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNc_3fdrchdW"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,result_ranking,'abstract','abstract','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz-cI7pC30SS",
        "outputId": "8ae2ecf7-1ceb-4c6a-cb69-011bcf105400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1372, 0.2375, 0.5394, 0.7655, 0.5949, 0.5893\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1350, 0.2382, 0.5432, 0.7259, 0.5344, 0.5353\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXa8uWAueTE2",
        "outputId": "969b9d74-e907-4c53-8d67-9e6d0bf69b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1644, 0.2146, 0.4953, 0.7255, 0.5254, 0.5194\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1473, 0.2179, 0.4919, 0.7169, 0.5090, 0.5087\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nikNiuJUEkjJ"
      },
      "source": [
        "### Query facet - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn9z9fALErrl"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,bg_ranking,'background_label','abstract','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASH5UVnDErig",
        "outputId": "7a2341ac-385e-46e9-c88c-a49d7fff45a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2239, 0.3000, 0.4427, 0.7596, 0.5747, 0.5687\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1904, 0.2969, 0.4660, 0.7717, 0.5807, 0.5852\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UUYZ9UBErW6"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,method_ranking,'method_label','abstract','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1jktQ2SErIA",
        "outputId": "f8e13ee2-306f-478b-b78a-7c139ddd2435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1976, 0.1188, 0.4115, 0.6132, 0.3669, 0.3754\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1539, 0.1149, 0.3906, 0.6146, 0.3603, 0.3625\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vk_N4F8Eq5q"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,result_ranking,'result_label','abstract','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yOwSYQfEqhU",
        "outputId": "89ab7857-4073-450f-b378-51e3accce0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1384, 0.2000, 0.4685, 0.7397, 0.5390, 0.5478\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1429, 0.2167, 0.4599, 0.7303, 0.5247, 0.5410\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gTxZpDmpIdz",
        "outputId": "1ff654e0-90b9-4bc0-f247-e6e482b2e9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1866, 0.2063, 0.4409, 0.7042, 0.4936, 0.4973\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1620, 0.2079, 0.4378, 0.7040, 0.4866, 0.4942\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWzWCFojrkzI"
      },
      "source": [
        "### Query facet - Candidate facet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZrtDb5Lr0D_"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,bg_ranking,'background_label','background_label','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZyMjLirzIq",
        "outputId": "d713d902-f257-43a2-bd4d-c50b368a0344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2019, 0.2687, 0.4001, 0.7833, 0.6101, 0.6062\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1786, 0.2625, 0.4054, 0.7793, 0.5857, 0.5928\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCD4QWVyry-z"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,method_ranking,'method_label','method_label','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR6ldZvIry2i",
        "outputId": "69af4bcc-27b6-4322-c4fa-ab876aea6569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2014, 0.1125, 0.3802, 0.6462, 0.3904, 0.3908\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1559, 0.1035, 0.3521, 0.6245, 0.3626, 0.3704\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdjYgOClrysG"
      },
      "outputs": [],
      "source": [
        "eval_model(0,'specter',sentences,result_ranking,'result_label','result_label','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oT0s4Ngryhr",
        "outputId": "c3f8268c-585e-475b-b110-6a7ee3e3dafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1455, 0.2187, 0.5213, 0.7349, 0.5423, 0.5369\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1443, 0.2344, 0.5038, 0.7261, 0.5251, 0.5328\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1-mcpRgrx7t",
        "outputId": "58342ec5-fb48-41f2-9fe7-75fcabd47b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1829, 0.2000, 0.4339, 0.7215, 0.5142, 0.5113\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-specter-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1592, 0.1990, 0.4204, 0.7085, 0.4893, 0.4969\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment specter --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTNg8MI_9Za"
      },
      "source": [
        "# scincl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP-a_CnouMod"
      },
      "source": [
        "### Query Abstract - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf47DKRZGz2B"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,bg_ranking,'abstract','abstract','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEax95rKkhbH",
        "outputId": "d783a85e-f387-4e69-880a-260cb6a5eab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2745, 0.3250, 0.4915, 0.8038, 0.6298, 0.6261\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2370, 0.3031, 0.4760, 0.8143, 0.6379, 0.6445\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqdgMQVvXNk_"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,method_ranking,'abstract','abstract','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOSCDQjGklID",
        "outputId": "576fe909-8134-4f95-c291-cdfbe2f9fb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1000, 0.1500, 0.4829, 0.6703, 0.4434, 0.4381\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1013, 0.1472, 0.4326, 0.6823, 0.4616, 0.4671\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmENr2sikljj"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,result_ranking,'abstract','abstract','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sirVUuYmdvi",
        "outputId": "68257c02-774b-467d-ad05-a2f1b12499ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1831, 0.2563, 0.5765, 0.8020, 0.6417, 0.6366\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1965, 0.2559, 0.5262, 0.7717, 0.5886, 0.5948\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frp-BPBumh6V",
        "outputId": "f71da73a-bdaf-4a02-d937-eaa65ab683dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1859, 0.2437, 0.5170, 0.7587, 0.5716, 0.5669\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1777, 0.2344, 0.4779, 0.7548, 0.5609, 0.5671\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O1cy5qIsljF"
      },
      "source": [
        "### Query facet - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4FObCO1sxAY"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,bg_ranking,'background_label','abstract','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWQXYKFnsw47",
        "outputId": "410153b7-44e8-41c7-fd5b-ec978b2051e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2827, 0.3563, 0.5570, 0.8167, 0.6762, 0.6763\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2311, 0.2969, 0.4582, 0.8072, 0.6276, 0.6363\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG6kA1wBsww3"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,method_ranking,'method_label','abstract','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsT-W9gYswqi",
        "outputId": "4066bfc9-e98a-4f97-878a-308f2353d195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0985, 0.1438, 0.4754, 0.6584, 0.4275, 0.4180\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1005, 0.1385, 0.4365, 0.6604, 0.4277, 0.4305\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7br74HIwswg0"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,result_ranking,'result_label','abstract','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UaRdsi_swZR",
        "outputId": "2c8af491-348e-4883-ba2b-e3700b866b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1678, 0.2063, 0.4674, 0.7271, 0.5138, 0.5161\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1757, 0.2365, 0.4868, 0.7294, 0.5242, 0.5343\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZK6abR6swRe",
        "outputId": "4bb5ffd1-73d8-4640-c7da-5652ca1b17e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1830, 0.2354, 0.4999, 0.7341, 0.5392, 0.5368\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1686, 0.2235, 0.4617, 0.7310, 0.5253, 0.5324\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdChexqrslWv"
      },
      "source": [
        "### Query facet - Candidate facet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znWC6YRBszAl"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,bg_ranking,'background_label','background_label','background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmKZCL1usy3R",
        "outputId": "a02a7f36-b505-413c-b0e9-e5427863e7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2868, 0.3625, 0.5538, 0.7995, 0.6363, 0.6353\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2188, 0.3375, 0.5197, 0.8029, 0.6253, 0.6334\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b60AHqHQsyvL"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,method_ranking,'method_label','method_label','method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hml1cDgWsynM",
        "outputId": "2e9f88c5-e614-4a4b-d791-f9492bba5bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1030, 0.1375, 0.4427, 0.6413, 0.4132, 0.4149\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0996, 0.1243, 0.3893, 0.6580, 0.4179, 0.4174\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXxA8celsyd2"
      },
      "outputs": [],
      "source": [
        "eval_model(3,'scincl',sentences,result_ranking,'result_label','result_label','result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gWF6UOnsyWi",
        "outputId": "1f6eaf12-9cfa-48ea-c3f9-e333d8ae6d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1752, 0.2188, 0.5023, 0.7291, 0.5344, 0.5350\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1618, 0.2177, 0.4610, 0.7280, 0.5213, 0.5339\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-9Gc0XRsyRJ",
        "outputId": "3eb9dc1e-7348-44f9-c5ec-7957e61f0586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1883, 0.2396, 0.4996, 0.7233, 0.5280, 0.5284\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-scincl-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1597, 0.2246, 0.4553, 0.7282, 0.5196, 0.5262\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment scincl --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb6_S5Bf5s2c"
      },
      "source": [
        "# sentbert-pp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lloiUBFFAiJ6"
      },
      "source": [
        "### Query facet - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ1F6Yu-et1q"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, bg_ranking, 'background_label', 'abstract', 'background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ki2rYPve96a",
        "outputId": "27e03167-e86a-4b11-9a23-7663e1a44e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ./test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2113, 0.3125, 0.4744, 0.7800, 0.6023, 0.5992\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ./test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2137, 0.3062, 0.4789, 0.7919, 0.6059, 0.6118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path /content/CSFCube-master/ --ranked_path ./ --experiment sentbert-pp --facet background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmLf2Kjon6pl"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, method_ranking, 'method_label', 'abstract', 'method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dn6AAqYoLDj",
        "outputId": "e32534f4-7aee-46b7-f9c3-d06cfd05b41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1008, 0.0938, 0.3884, 0.5833, 0.3204, 0.3208\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1084, 0.1052, 0.3671, 0.5979, 0.3313, 0.3330\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdS4spAI9RK_"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, result_ranking, 'result_label', 'abstract', 'result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7yJQlIg9Rzn",
        "outputId": "a9adb121-dd5f-4762-e0e5-11bcb0548c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1321, 0.2250, 0.5178, 0.7648, 0.5777, 0.5800\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1298, 0.2042, 0.4706, 0.7176, 0.5014, 0.5144\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPqmiS8BpxHk",
        "outputId": "5ce87c82-0f7a-48b5-a540-8c730a2994fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1481, 0.2104, 0.4602, 0.7094, 0.5001, 0.5000\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1494, 0.2033, 0.4376, 0.7004, 0.4766, 0.4835\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHHmzr8FAspY"
      },
      "source": [
        "### Query Abstract - Candidate Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvgx2_zIAxxb"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, bg_ranking, 'abstract', 'abstract', 'background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2R3WHMvA2C4",
        "outputId": "243de0cd-78d0-481e-ac3f-2f5396b90c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2081, 0.3125, 0.4411, 0.7655, 0.5756, 0.5810\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2009, 0.2969, 0.4458, 0.7743, 0.5770, 0.5853\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk1p_GZ8fMZP"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, method_ranking, 'abstract', 'abstract', 'method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6DbQK6fMTw",
        "outputId": "08aed662-4192-4d20-dff8-1c397f6ea99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0983, 0.1313, 0.3557, 0.5817, 0.3254, 0.3182\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0979, 0.1267, 0.3799, 0.6049, 0.3554, 0.3573\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b47O9m9fMJz"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, result_ranking, 'abstract', 'abstract', 'result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD5Dr_gRfL6R",
        "outputId": "d4cf3e8c-3c65-4f94-e552-5b19bbb99206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1635, 0.2125, 0.4632, 0.7580, 0.5771, 0.5794\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1480, 0.1868, 0.3942, 0.6987, 0.4791, 0.4927\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la8epnvnfNkb",
        "outputId": "63df0a41-4d17-453c-cd39-8bb0859466a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1566, 0.2188, 0.4200, 0.7017, 0.4927, 0.4928\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1479, 0.2017, 0.4055, 0.6907, 0.4680, 0.4760\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet all\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALpEsSD_uYE3"
      },
      "source": [
        "### Query facet - Candidate facet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2bVnWGEueXr"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, bg_ranking, 'background_label', 'background_label', 'background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRSJ4FWRufnF",
        "outputId": "73e0b92c-f151-4785-e3a3-790c1d481a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2204, 0.3000, 0.4579, 0.7936, 0.6175, 0.6189\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-background-perq.csv\n",
            "Total queries: 16; Total candidates: 1877\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.2251, 0.3156, 0.5010, 0.8033, 0.6242, 0.6316\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet background\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHf_l5Dwufdn"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, method_ranking, 'method_label', 'method_label', 'method')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXAO_sxSufVm",
        "outputId": "a4855847-ec3b-4b2d-cfa5-8fa41edf84c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0827, 0.1063, 0.3646, 0.5849, 0.3340, 0.3396\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-method-perq.csv\n",
            "Total queries: 17; Total candidates: 2174\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.0873, 0.1087, 0.3189, 0.5848, 0.3089, 0.3168\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet method\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8xno9kIufMt"
      },
      "outputs": [],
      "source": [
        "eval_model(10, 'sentbert-pp', sentences, result_ranking, 'result_label', 'result_label', 'result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bi3DGQque9u",
        "outputId": "c5de995b-c064-4c8f-e74b-03526de4e785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1243, 0.2250, 0.5118, 0.7531, 0.5571, 0.5681\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-result-perq.csv\n",
            "Total queries: 17; Total candidates: 2193\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1104, 0.2125, 0.4746, 0.7188, 0.5068, 0.5230\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet result\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LarTPdrueuu",
        "outputId": "23442b32-0e3e-4115-e770-41bf4e12ac19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSFCube-master\n",
            "EVAL SPLIT: dev\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1424, 0.2104, 0.4447, 0.7106, 0.5029, 0.5089\n",
            "\n",
            "EVAL SPLIT: test\n",
            "Reading facet: background\n",
            "Gold query pids: 16\n",
            "Valid ranked query pids: 16\n",
            "Reading facet: method\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Reading facet: result\n",
            "Gold query pids: 17\n",
            "Valid ranked query pids: 17\n",
            "Total queries: 50\n",
            "Precision and recall at rank: 20\n",
            "Wrote: ../test-pid2pool-csfcube-sentbert-pp-all-perq.csv\n",
            "Total queries: 50; Total candidates: 6244\n",
            "R-Precision; Precision@20; Recall@20; NDCG; NDCG@20; NDCG%20\n",
            "0.1392, 0.2100, 0.4291, 0.7000, 0.4766, 0.4872\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd CSFCube-master\n",
        "!python /content/CSFCube-master/eval_scripts/ranking_eval.py eval_pool_ranking --gold_path ./ --ranked_path ../ --experiment sentbert-pp --facet all\n",
        "%cd .."
      ]
    }
  ]
}